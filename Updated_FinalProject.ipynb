{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FinalProject2025.pdf**\n",
    "\n",
    "***2.2 Neuronal functional connectivity analysis***\n",
    "\n",
    "Data: The dataset include 130 simultaneously recorded neuros from the gustatory cortex while the rat learn to associate a novel taste with malaise. The data\n",
    "is located in the Moodle page (titled \"Anan3\"). See more instractions there.\n",
    "\n",
    "Main goal: Estimate the connection strength between the neurons to create\n",
    "a functional connectivity map.\n",
    "\n",
    "Tasks:\n",
    "1. First define the connectivity matrix between neurons. Use some statistic\n",
    "to test for significant connectivity\n",
    "2. Compute a measure of the strength of the connection.\n",
    "3. Use some methods to visualize the connectivity other than a matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**instruction from moodle page under \"Anan3\"**\n",
    "\n",
    "***Assessing  neuronal  network functional connectivity from spike trains***\n",
    "\n",
    "**Data**: spiking activity of ensemble of ~130 neurons in the gustatory and somatosensory cortices\n",
    "recorded continuously (across ~30 hours) as rats learn to associate a novel taste with gastric malaise.\n",
    "\n",
    "**Your task**: find the connectivity between pairs of neurons in the network to show the changes across\n",
    "time, and learning. (Hint: cross correlation…)\n",
    "\n",
    "**Bonus**: use some cool packages for network representation to show the network topology. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input files:\n",
    "\n",
    "cluster_info.tsv – a Tab-separated values file which contains information about the sorted neurons.\n",
    "Each line contains the information for one optional neuron (sorted cluster). For your analysis only\n",
    "take neurons (clusters) that their “group” value is “good” (should be around 130).\n",
    "\n",
    "spike_seconds.npy – a list of spike times (in seconds)\n",
    "\n",
    "spike_clusters.npy – a list of cluster ids, which correspond to the spikes in spike_seconds.npy\n",
    "\n",
    "so if you load both files:\n",
    "\n",
    "cluster_ids = np.load(‘spike_clusters.npy’)\n",
    "\n",
    "st = np.load('spike_seconds.npy')\n",
    "\n",
    "if cluster_ids[0] = 5 and st[0] = 11.56, it means that there was a spike for cluster 5 at 11.56 seconds\n",
    "from the beginning of the recording."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load and Filter Data\n",
    "We first load the spike time data and filter it to include only 'good' neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_spike_data(spike_times_file, spike_clusters_file, cluster_info_file):\n",
    "    \"\"\"Load and filter spike data for 'good' neurons.\"\"\"\n",
    "    spike_times = np.load(spike_times_file)  # Load spike times (in seconds)\n",
    "    spike_clusters = np.load(spike_clusters_file)  # Load neuron IDs\n",
    "\n",
    "    # Load cluster info and filter for 'good' neurons\n",
    "    cluster_info = pd.read_csv(cluster_info_file, sep='\\t')\n",
    "    good_neurons = cluster_info[cluster_info['group'] == 'good']['cluster_id'].values\n",
    "\n",
    "    # Filter spikes for 'good' neurons\n",
    "    mask = np.isin(spike_clusters, good_neurons)\n",
    "    filtered_spike_clusters = spike_clusters[mask]\n",
    "    filtered_spike_times = spike_times[mask]\n",
    "\n",
    "    return filtered_spike_times, filtered_spike_clusters, good_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of good neurons: 131\n",
      "\n",
      "First few spike times: [[0.00833343]\n",
      " [0.00853344]\n",
      " [0.00916678]\n",
      " [0.01016679]\n",
      " [0.01626686]\n",
      " [0.02190027]\n",
      " [0.02316695]\n",
      " [0.03030037]\n",
      " [0.03130038]\n",
      " [0.03410042]]\n",
      "\n",
      "First few spike clusters: [154 923 917 845 112  70 251 954 845 921]\n"
     ]
    }
   ],
   "source": [
    "# sample output\n",
    "\n",
    "spike_times, spike_clusters, good_neurons = load_spike_data(\n",
    "    \"spike_seconds.npy\", \"spike_clusters.npy\", \"cluster_info.tsv\"\n",
    ")\n",
    "print(\"Number of good neurons:\", len(good_neurons))\n",
    "print(\"\\nFirst few spike times:\", spike_times[:10])\n",
    "print(\"\\nFirst few spike clusters:\", spike_clusters[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20530010 20530010\n"
     ]
    }
   ],
   "source": [
    "print(len(spike_times), len(spike_clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spike_times shape: (20530010, 1)\n",
      "spike_clusters shape: (20530010,)\n"
     ]
    }
   ],
   "source": [
    "print(\"spike_times shape:\", spike_times.shape)\n",
    "print(\"spike_clusters shape:\", spike_clusters.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_times = spike_times.flatten()  # Convert (N,1) → (N,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_segments(spike_times, segment_duration):\n",
    "    \"\"\"Splits spike times into fixed-size segments.\"\"\"\n",
    "    total_duration = np.max(spike_times)\n",
    "    # num_segments = int(np.ceil(total_duration / segment_duration))\n",
    "    num_segments = int(np.max(spike_times) // segment_duration)  # Only full segments\n",
    "    \n",
    "    segment_ranges = [\n",
    "        # (i * segment_duration, min((i + 1) * segment_duration, total_duration))\n",
    "        (i * segment_duration, (i + 1) * segment_duration) \n",
    "        for i in range(num_segments)\n",
    "    ]\n",
    "    \n",
    "    return segment_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_spike_trains(spike_times, spike_clusters, neuron_ids, segment_range, bin_size=0.001, binary_mode=False):\n",
    "    \"\"\"\n",
    "    Converts spike timestamps into a fixed-size binned spike train matrix.\n",
    "\n",
    "    Parameters:\n",
    "    - binary_mode (bool): If True, store 0/1 (binary); otherwise, count spikes.\n",
    "\n",
    "    Returns:\n",
    "    - binned_spike_train (np.array): Fixed-size binned spike matrix (neurons × time bins).\n",
    "    \"\"\"\n",
    "    start_time, end_time = segment_range\n",
    "    num_bins = int((end_time - start_time) / bin_size)  \n",
    "\n",
    "    # Select spikes within this segment\n",
    "    mask = (spike_times >= start_time) & (spike_times < end_time)\n",
    "    segment_spike_times = spike_times[mask] - start_time  \n",
    "    segment_spike_clusters = spike_clusters[mask]\n",
    "\n",
    "    # Initialize spike train matrix (ensuring fixed shape)\n",
    "    binned_spike_train = np.zeros((len(neuron_ids), num_bins), dtype=np.uint8)\n",
    "\n",
    "    # Convert spike times to bin indices\n",
    "    bin_indices = (segment_spike_times / bin_size).astype(int)\n",
    "\n",
    "    # Map neuron ID to row index for fast lookup\n",
    "    neuron_idx_map = {neuron: i for i, neuron in enumerate(neuron_ids)}\n",
    "\n",
    "    # Populate the matrix\n",
    "    for spike_idx, neuron_id in enumerate(segment_spike_clusters):\n",
    "        if neuron_id in neuron_idx_map:\n",
    "            row = neuron_idx_map[neuron_id]\n",
    "            col = bin_indices[spike_idx], num_bins - 1\n",
    "            if binary_mode:\n",
    "                binned_spike_train[row, col] = 1  # Store 0/1 only\n",
    "            else:\n",
    "                binned_spike_train[row, col] += 1  # Store spike count\n",
    "\n",
    "    return binned_spike_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing & Saving Segment 1/15: 0s to 7200s\n",
      "✅ Segment 1 saved: binned_segments/binned_segment_0.npz\n",
      "Processing & Saving Segment 2/15: 7200s to 14400s\n",
      "✅ Segment 2 saved: binned_segments/binned_segment_1.npz\n",
      "Processing & Saving Segment 3/15: 14400s to 21600s\n",
      "✅ Segment 3 saved: binned_segments/binned_segment_2.npz\n",
      "Processing & Saving Segment 4/15: 21600s to 28800s\n",
      "✅ Segment 4 saved: binned_segments/binned_segment_3.npz\n",
      "Processing & Saving Segment 5/15: 28800s to 36000s\n",
      "✅ Segment 5 saved: binned_segments/binned_segment_4.npz\n",
      "Processing & Saving Segment 6/15: 36000s to 43200s\n",
      "✅ Segment 6 saved: binned_segments/binned_segment_5.npz\n",
      "Processing & Saving Segment 7/15: 43200s to 50400s\n",
      "✅ Segment 7 saved: binned_segments/binned_segment_6.npz\n",
      "Processing & Saving Segment 8/15: 50400s to 57600s\n",
      "✅ Segment 8 saved: binned_segments/binned_segment_7.npz\n",
      "Processing & Saving Segment 9/15: 57600s to 64800s\n",
      "✅ Segment 9 saved: binned_segments/binned_segment_8.npz\n",
      "Processing & Saving Segment 10/15: 64800s to 72000s\n",
      "✅ Segment 10 saved: binned_segments/binned_segment_9.npz\n",
      "Processing & Saving Segment 11/15: 72000s to 79200s\n",
      "✅ Segment 11 saved: binned_segments/binned_segment_10.npz\n",
      "Processing & Saving Segment 12/15: 79200s to 86400s\n",
      "✅ Segment 12 saved: binned_segments/binned_segment_11.npz\n",
      "Processing & Saving Segment 13/15: 86400s to 93600s\n",
      "✅ Segment 13 saved: binned_segments/binned_segment_12.npz\n",
      "Processing & Saving Segment 14/15: 93600s to 100800s\n",
      "✅ Segment 14 saved: binned_segments/binned_segment_13.npz\n",
      "Processing & Saving Segment 15/15: 100800s to 108000s\n",
      "✅ Segment 15 saved: binned_segments/binned_segment_14.npz\n",
      "✅ All segments processed and saved to disk.\n"
     ]
    }
   ],
   "source": [
    "def process_and_save_segments(spike_times, spike_clusters, neuron_ids, bin_size, segment_duration):\n",
    "    \"\"\"\n",
    "    Processes and saves each fixed-size segment to disk to avoid memory issues.\n",
    "\n",
    "    Parameters:\n",
    "    - spike_times (np.array): Array of spike times in seconds.\n",
    "    - spike_clusters (np.array): Corresponding neuron IDs for each spike.\n",
    "    - neuron_ids (np.array): Unique neuron identifiers (good neurons).\n",
    "    - bin_size (float): Time bin size in seconds.\n",
    "    - segment_duration (int): Duration of each segment in seconds.\n",
    "\n",
    "    Saves:\n",
    "    - Each segment's binned spike train as a `.npz` file.\n",
    "    \"\"\"\n",
    "    output_dir = \"binned_segments\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    segment_ranges = split_into_segments(spike_times, segment_duration)\n",
    "    \n",
    "    for idx, segment_range in enumerate(segment_ranges):\n",
    "        print(f\"Processing & Saving Segment {idx + 1}/{len(segment_ranges)}: {segment_range[0]}s to {segment_range[1]}s\")\n",
    "\n",
    "        # Bin spike trains for the segment\n",
    "        binned_data = bin_spike_trains(spike_times, spike_clusters, neuron_ids, segment_range, bin_size)\n",
    "\n",
    "        # Save to compressed .npz file\n",
    "        np.savez_compressed(\n",
    "            os.path.join(output_dir, f\"binned_segment_{idx}.npz\"),\n",
    "            spike_train=binned_data,\n",
    "            neuron_ids=neuron_ids\n",
    "        )\n",
    "\n",
    "        print(f\"✅ Segment {idx + 1} saved: {output_dir}/binned_segment_{idx}.npz\")\n",
    "\n",
    "# Run processing with memory-efficient saving\n",
    "bin_size = 0.001  # 1 ms = 1000 Hz binning\n",
    "segment_duration = 7200  # 2 hours = 7200 seconds\n",
    "\n",
    "process_and_save_segments(spike_times, spike_clusters, good_neurons, bin_size, segment_duration)\n",
    "\n",
    "print(\"✅ All segments processed and saved to disk.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import correlate\n",
    "\n",
    "def compute_cross_correlation(binned_spike_train, max_lag=40):\n",
    "    \"\"\"\n",
    "    Computes the cross-correlation function for all neuron pairs.\n",
    "\n",
    "    Parameters:\n",
    "    - binned_spike_train (np.array): Shape (num_neurons, num_bins), 0/1 values.\n",
    "    - max_lag (int): Max time lag in milliseconds.\n",
    "\n",
    "    Returns:\n",
    "    - cross_corr_matrices (dict): Dictionary where keys are neuron pairs (i, j),\n",
    "      values are the cross-correlation functions.\n",
    "    \"\"\"\n",
    "    num_neurons = binned_spike_train.shape[0]\n",
    "    cross_corr_matrices = {}\n",
    "\n",
    "    for i in range(num_neurons):\n",
    "        for j in range(num_neurons):\n",
    "            if i != j:  # Skip self-correlation\n",
    "                corr = correlate(binned_spike_train[i], binned_spike_train[j], mode='full')\n",
    "                lag_center = len(corr) // 2\n",
    "                cross_corr_matrices[(i, j)] = corr[lag_center - max_lag : lag_center + max_lag]  # ±max_lag region\n",
    "\n",
    "    return cross_corr_matrices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m binned_spike_train \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspike_train\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Compute cross-correlation\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m cross_corr_matrices \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_cross_correlation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbinned_spike_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[29], line 21\u001b[0m, in \u001b[0;36mcompute_cross_correlation\u001b[1;34m(binned_spike_train, max_lag)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_neurons):\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m j:  \u001b[38;5;66;03m# Skip self-correlation\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m         corr \u001b[38;5;241m=\u001b[39m \u001b[43mcorrelate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbinned_spike_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinned_spike_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfull\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m         lag_center \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(corr) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m     23\u001b[0m         cross_corr_matrices[(i, j)] \u001b[38;5;241m=\u001b[39m corr[lag_center \u001b[38;5;241m-\u001b[39m max_lag : lag_center \u001b[38;5;241m+\u001b[39m max_lag]  \u001b[38;5;66;03m# ±max_lag region\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\97250\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\signal\\_signaltools.py:247\u001b[0m, in \u001b[0;36mcorrelate\u001b[1;34m(in1, in2, mode, method)\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;66;03m# this either calls fftconvolve or this function with method=='direct'\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfft\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 247\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconvolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43min1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_reverse_and_conj\u001b[49m\u001b[43m(\u001b[49m\u001b[43min2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdirect\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;66;03m# fastpath to faster numpy.correlate for 1d inputs when possible\u001b[39;00m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _np_conv_ok(in1, in2, mode):\n",
      "File \u001b[1;32mc:\\Users\\97250\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\signal\\_signaltools.py:1419\u001b[0m, in \u001b[0;36mconvolve\u001b[1;34m(in1, in2, mode, method)\u001b[0m\n\u001b[0;32m   1416\u001b[0m     method \u001b[38;5;241m=\u001b[39m choose_conv_method(volume, kernel, mode\u001b[38;5;241m=\u001b[39mmode)\n\u001b[0;32m   1418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfft\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m-> 1419\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mfftconvolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvolume\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1420\u001b[0m     result_type \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mresult_type(volume, kernel)\n\u001b[0;32m   1421\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result_type\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m'\u001b[39m}:\n",
      "File \u001b[1;32mc:\\Users\\97250\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\signal\\_signaltools.py:675\u001b[0m, in \u001b[0;36mfftconvolve\u001b[1;34m(in1, in2, mode, axes)\u001b[0m\n\u001b[0;32m    670\u001b[0m s2 \u001b[38;5;241m=\u001b[39m in2\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    672\u001b[0m shape \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mmax\u001b[39m((s1[i], s2[i])) \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m axes \u001b[38;5;28;01melse\u001b[39;00m s1[i] \u001b[38;5;241m+\u001b[39m s2[i] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    673\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(in1\u001b[38;5;241m.\u001b[39mndim)]\n\u001b[1;32m--> 675\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43m_freq_domain_conv\u001b[49m\u001b[43m(\u001b[49m\u001b[43min1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcalc_fast_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _apply_conv_mode(ret, s1, s2, mode, axes)\n",
      "File \u001b[1;32mc:\\Users\\97250\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\signal\\_signaltools.py:515\u001b[0m, in \u001b[0;36m_freq_domain_conv\u001b[1;34m(in1, in2, axes, shape, calc_fast_len)\u001b[0m\n\u001b[0;32m    512\u001b[0m sp1 \u001b[38;5;241m=\u001b[39m fft(in1, fshape, axes\u001b[38;5;241m=\u001b[39maxes)\n\u001b[0;32m    513\u001b[0m sp2 \u001b[38;5;241m=\u001b[39m fft(in2, fshape, axes\u001b[38;5;241m=\u001b[39maxes)\n\u001b[1;32m--> 515\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mifft\u001b[49m\u001b[43m(\u001b[49m\u001b[43msp1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msp2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m calc_fast_len:\n\u001b[0;32m    518\u001b[0m     fslice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m([\u001b[38;5;28mslice\u001b[39m(sz) \u001b[38;5;28;01mfor\u001b[39;00m sz \u001b[38;5;129;01min\u001b[39;00m shape])\n",
      "File \u001b[1;32mc:\\Users\\97250\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\fft\\_backend.py:28\u001b[0m, in \u001b[0;36m_ScipyBackend.__ua_function__\u001b[1;34m(method, args, kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\97250\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\fft\\_basic_backend.py:132\u001b[0m, in \u001b[0;36mirfftn\u001b[1;34m(x, s, axes, norm, overwrite_x, workers, plan)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mirfftn\u001b[39m(x, s\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, axes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    131\u001b[0m            overwrite_x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, plan\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_execute_nD\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mirfftn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pocketfft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mirfftn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[43m                       \u001b[49m\u001b[43moverwrite_x\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplan\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\97250\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\fft\\_basic_backend.py:47\u001b[0m, in \u001b[0;36m_execute_nD\u001b[1;34m(func_str, pocketfft_func, x, s, axes, norm, overwrite_x, workers, plan)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_numpy(xp):\n\u001b[0;32m     46\u001b[0m     x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\n\u001b[1;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpocketfft_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m                          \u001b[49m\u001b[43moverwrite_x\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m norm \u001b[38;5;241m=\u001b[39m _validate_fft_args(workers, plan, norm)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(xp, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfft\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\97250\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\fft\\_pocketfft\\basic.py:218\u001b[0m, in \u001b[0;36mc2rn\u001b[1;34m(forward, x, s, axes, norm, overwrite_x, workers, plan)\u001b[0m\n\u001b[0;32m    215\u001b[0m tmp, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(_fix_shape(tmp, shape, axes))\n\u001b[0;32m    217\u001b[0m \u001b[38;5;66;03m# Note: overwrite_x is not utilized\u001b[39;00m\n\u001b[1;32m--> 218\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpfft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc2r\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtmp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlastsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load a segment\n",
    "segment_idx = 0\n",
    "file_path = f\"binned_segments/binned_segment_{segment_idx}.npz\"\n",
    "data = np.load(file_path)\n",
    "binned_spike_train = data[\"spike_train\"]\n",
    "\n",
    "# Compute cross-correlation\n",
    "cross_corr_matrices = compute_cross_correlation(binned_spike_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
